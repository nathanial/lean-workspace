/-
  AgentMail.Git.Guard - Git pre-commit guard script generation
-/
import Lean.Data.Json

namespace AgentMail.Git.Guard

/-- Marker used to identify our chain-runner scripts -/
def chainRunnerMarker : String := "# mcp-agent-mail chain-runner"

/-- Marker used to identify our guard plugin scripts -/
def guardPluginMarker : String := "# mcp-agent-mail guard hook"

/-- Render the chain-runner shell script for a git hook.
    This script executes all scripts in hooks.d/<hookName>/ directory in sorted order. -/
def renderChainRunner (hookName : String) : String :=
  String.intercalate "\n" [
    "#!/usr/bin/env python3",
    s!"{chainRunnerMarker} ({hookName})",
    "import os",
    "import sys",
    "import stat",
    "import subprocess",
    "from pathlib import Path",
    "",
    "HOOK_DIR = Path(__file__).parent",
    s!"RUN_DIR = HOOK_DIR / 'hooks.d' / '{hookName}'",
    s!"ORIG = HOOK_DIR / '{hookName}.orig'",
    "",
    "def _is_exec(p: Path) -> bool:",
    "    try:",
    "        st = p.stat()",
    "        return bool(st.st_mode & (stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH))",
    "    except Exception:",
    "        return False",
    "",
    "def _list_execs() -> list[Path]:",
    "    if not RUN_DIR.exists() or not RUN_DIR.is_dir():",
    "        return []",
    "    items = sorted([p for p in RUN_DIR.iterdir() if p.is_file()], key=lambda p: p.name)",
    "    if os.name == 'posix':",
    "        try:",
    "            items = [p for p in items if _is_exec(p)]",
    "        except Exception:",
    "            pass",
    "    return items",
    "",
    "def _run_child(path: Path, *, stdin_bytes=None):",
    "    if os.name != 'posix' and path.suffix.lower() == '.py':",
    "        return subprocess.run(['python', str(path)], input=stdin_bytes, check=False).returncode",
    "    return subprocess.run([str(path)], input=stdin_bytes, check=False).returncode",
    ""
  ] ++
  (if hookName == "pre-push" then
    String.intercalate "\n" [
      "# Read STDIN once (Git passes ref tuples); forward to children",
      "stdin_bytes = sys.stdin.buffer.read()",
      "for exe in _list_execs():",
      "    rc = _run_child(exe, stdin_bytes=stdin_bytes)",
      "    if rc != 0:",
      "        sys.exit(rc)",
      "",
      "if ORIG.exists():",
      "    rc = _run_child(ORIG, stdin_bytes=stdin_bytes)",
      "    if rc != 0:",
      "        sys.exit(rc)",
      "sys.exit(0)"
    ]
  else
    String.intercalate "\n" [
      "for exe in _list_execs():",
      "    rc = _run_child(exe)",
      "    if rc != 0:",
      "        sys.exit(rc)",
      "",
      "if ORIG.exists():",
      "    rc = _run_child(ORIG)",
      "    if rc != 0:",
      "        sys.exit(rc)",
      "sys.exit(0)"
    ]) ++ "\n"

/-- Render the pre-commit guard Python script.
    This script checks staged files against file reservations. -/
def renderPrecommitGuard (storageRoot : String) (fileReservationsDir : String) : String :=
  let normalizedStorage := storageRoot.replace "\\" "/"
  let normalizedFileRes := fileReservationsDir.replace "\\" "/"
  let storageRootJson := Lean.Json.compress (Lean.Json.str normalizedStorage)
  let fileResJson := Lean.Json.compress (Lean.Json.str normalizedFileRes)
  String.intercalate "\n" [
    "#!/usr/bin/env python3",
    s!"{guardPluginMarker} (pre-commit)",
    "import json",
    "import os",
    "import sys",
    "import subprocess",
    "from pathlib import Path",
    "import fnmatch as _fn",
    "from datetime import datetime, timezone",
    "",
    "# Optional Git pathspec support (preferred when available)",
    "try:",
    "    from pathspec import PathSpec as _PS  # type: ignore[import-not-found]",
    "    from pathspec.patterns.gitwildmatch import GitWildMatchPattern as _GWM  # type: ignore[import-not-found]",
    "except Exception:",
    "    _PS = None  # type: ignore[assignment]",
    "    _GWM = None  # type: ignore[assignment]",
    "",
    s!"FILE_RESERVATIONS_DIR = Path({fileResJson})",
    s!"STORAGE_ROOT = Path({storageRootJson})",
    "",
    "# Gate variables (presence) and mode",
    "GATE = (os.environ.get(\"WORKTREES_ENABLED\",\"0\") or os.environ.get(\"GIT_IDENTITY_ENABLED\",\"0\") or \"0\")",
    "",
    "# Exit early if gate is not enabled (WORKTREES_ENABLED=0 and GIT_IDENTITY_ENABLED=0)",
    "if GATE.strip().lower() not in {\"1\",\"true\",\"t\",\"yes\",\"y\"}:",
    "    sys.exit(0)",
    "",
    "# Advisory/blocking mode: default to 'block' unless explicitly set to 'warn'.",
    "MODE = (os.environ.get(\"AGENT_MAIL_GUARD_MODE\",\"block\") or \"block\").strip().lower()",
    "ADVISORY = MODE in {\"warn\",\"advisory\",\"adv\"}",
    "",
    "# Emergency bypass",
    "if (os.environ.get(\"AGENT_MAIL_BYPASS\",\"0\") or \"0\").strip().lower() in {\"1\",\"true\",\"t\",\"yes\",\"y\"}:",
    "    sys.stderr.write(\"[pre-commit] bypass enabled via AGENT_MAIL_BYPASS=1\\n\")",
    "    sys.exit(0)",
    "AGENT_NAME = os.environ.get(\"AGENT_NAME\")",
    "if not AGENT_NAME:",
    "    sys.stderr.write(\"[pre-commit] AGENT_NAME environment variable is required.\\n\")",
    "    sys.exit(1)",
    "",
    "# Collect staged paths (name-only) and expand renames/moves (old+new)",
    "paths = []",
    "try:",
    "    co = subprocess.run([\"git\",\"diff\",\"--cached\",\"--name-only\",\"-z\",\"--diff-filter=ACMRDTU\"],",
    "                        check=True,capture_output=True)",
    "    data = co.stdout.decode(\"utf-8\",\"ignore\")",
    "    for p in data.split(\"\\x00\"):",
    "        if p:",
    "            paths.append(p)",
    "    # Rename detection: capture both old and new names",
    "    cs = subprocess.run([\"git\",\"diff\",\"--cached\",\"--name-status\",\"-M\",\"-z\"],",
    "                        check=True,capture_output=True)",
    "    sdata = cs.stdout.decode(\"utf-8\",\"ignore\")",
    "    parts = [x for x in sdata.split(\"\\x00\") if x]",
    "    i = 0",
    "    while i < len(parts):",
    "        status = parts[i]",
    "        i += 1",
    "        if status.startswith(\"R\") and i + 1 < len(parts):",
    "            oldp = parts[i]; newp = parts[i+1]; i += 2",
    "            if oldp: paths.append(oldp)",
    "            if newp: paths.append(newp)",
    "        else:",
    "            # Status followed by one path",
    "            if i < len(parts):",
    "                pth = parts[i]; i += 1",
    "                if pth: paths.append(pth)",
    "except Exception:",
    "    pass",
    "",
    "if not paths:",
    "    sys.exit(0)",
    "",
    "# Local conflict detection against FILE_RESERVATIONS_DIR",
    "def _now_utc():",
    "    return datetime.now(timezone.utc)",
    "def _parse_iso(value):",
    "    if not value:",
    "        return None",
    "    try:",
    "        text = value",
    "        if text.endswith(\"Z\"):",
    "            text = text[:-1] + \"+00:00\"",
    "        dt = datetime.fromisoformat(text)",
    "        if dt.tzinfo is None or dt.tzinfo.utcoffset(dt) is None:",
    "            dt = dt.replace(tzinfo=timezone.utc)",
    "        return dt.astimezone(timezone.utc)",
    "    except Exception:",
    "        return None",
    "def _not_expired(expires_ts):",
    "    parsed = _parse_iso(expires_ts)",
    "    if parsed is None:",
    "        return True",
    "    return parsed > _now_utc()",
    "def _compile_one(patt):",
    "    q = patt.replace(\"\\\\\",\"/\")",
    "    if _PS and _GWM:",
    "        try:",
    "            return _PS.from_lines(_GWM, [q])",
    "        except Exception:",
    "            return None",
    "    return None",
    "",
    "# Phase 1: Pre-load and compile all reservation patterns ONCE",
    "compiled_patterns = []",
    "all_pattern_strings = []",
    "seen_ids = set()",
    "try:",
    "    for f in FILE_RESERVATIONS_DIR.iterdir():",
    "        if not f.name.endswith('.json'):",
    "            continue",
    "        try:",
    "            data = json.loads(f.read_text(encoding='utf-8'))",
    "        except Exception:",
    "            continue",
    "        recs = data if isinstance(data, list) else [data]",
    "        for r in recs:",
    "            if not isinstance(r, dict):",
    "                continue",
    "            rid = r.get('id')",
    "            if rid is not None:",
    "                rid_key = str(rid)",
    "                if rid_key in seen_ids:",
    "                    continue",
    "                seen_ids.add(rid_key)",
    "            patt = (r.get('path_pattern') or '').strip()",
    "            if not patt:",
    "                continue",
    "            holder = (r.get('agent') or '').strip()",
    "            exclusive = r.get('exclusive', True)",
    "            expires = (r.get('expires_ts') or '').strip()",
    "            if not exclusive:",
    "                continue",
    "            if holder and holder == AGENT_NAME:",
    "                continue",
    "            if not _not_expired(expires):",
    "                continue",
    "            # Pre-compile pattern ONCE (not per-path)",
    "            spec = _compile_one(patt)",
    "            patt_norm = patt.replace('\\\\','/').lstrip('/')",
    "            compiled_patterns.append((spec, patt, patt_norm, holder))",
    "            all_pattern_strings.append(patt_norm)",
    "except Exception:",
    "    compiled_patterns = []",
    "    all_pattern_strings = []",
    "",
    "# Phase 2: Build union PathSpec for fast-path rejection",
    "union_spec = None",
    "if _PS and _GWM and all_pattern_strings:",
    "    try:",
    "        union_spec = _PS.from_lines(_GWM, all_pattern_strings)",
    "    except Exception:",
    "        union_spec = None",
    "",
    "# Phase 3: Check paths against compiled patterns",
    "conflicts = []",
    "if compiled_patterns:",
    "    for p in paths:",
    "        norm = p.replace('\\\\','/').lstrip('/')",
    "        # Fast-path: if union_spec exists and path doesn't match ANY pattern, skip",
    "        if union_spec is not None and not union_spec.match_file(norm):",
    "            continue",
    "        # Detailed matching for conflict attribution",
    "        for spec, patt, patt_norm, holder in compiled_patterns:",
    "            matched = spec.match_file(norm) if spec is not None else _fn.fnmatch(norm, patt_norm)",
    "            if matched:",
    "                conflicts.append((patt, p, holder))",
    "if conflicts:",
    "    sys.stderr.write(\"Exclusive file_reservation conflicts detected\\n\")",
    "    for patt, path, holder in conflicts[:10]:",
    "        sys.stderr.write(f\"- {path} matches {patt} (holder: {holder})\\n\")",
    "    if ADVISORY:",
    "        sys.exit(0)",
    "    sys.exit(1)",
    "sys.exit(0)"
  ] ++ "\n"

/-- Render the pre-push guard Python script.
    Similar to pre-commit but runs before push. -/
def renderPrepushGuard (_storageRoot : String) (fileReservationsDir : String) : String :=
  let normalizedFileRes := fileReservationsDir.replace "\\" "/"
  let fileResJson := Lean.Json.compress (Lean.Json.str normalizedFileRes)
  String.intercalate "\n" [
    "#!/usr/bin/env python3",
    s!"{guardPluginMarker} (pre-push)",
    "import json",
    "import os",
    "import sys",
    "import subprocess",
    "from pathlib import Path",
    "import fnmatch as _fn",
    "from datetime import datetime, timezone",
    "",
    "# Optional Git pathspec support (preferred when available)",
    "try:",
    "    from pathspec import PathSpec as _PS  # type: ignore[import-not-found]",
    "    from pathspec.patterns.gitwildmatch import GitWildMatchPattern as _GWM  # type: ignore[import-not-found]",
    "except Exception:",
    "    _PS = None  # type: ignore[assignment]",
    "    _GWM = None  # type: ignore[assignment]",
    "",
    s!"FILE_RESERVATIONS_DIR = Path({fileResJson})",
    "",
    "# Gate variables (presence) and mode",
    "GATE = (os.environ.get(\"WORKTREES_ENABLED\",\"0\") or os.environ.get(\"GIT_IDENTITY_ENABLED\",\"0\") or \"0\")",
    "",
    "# Exit early if gate is not enabled (WORKTREES_ENABLED=0 and GIT_IDENTITY_ENABLED=0)",
    "if GATE.strip().lower() not in {\"1\",\"true\",\"t\",\"yes\",\"y\"}:",
    "    sys.exit(0)",
    "",
    "MODE = (os.environ.get(\"AGENT_MAIL_GUARD_MODE\",\"block\") or \"block\").strip().lower()",
    "ADVISORY = MODE in {\"warn\",\"advisory\",\"adv\"}",
    "if (os.environ.get(\"AGENT_MAIL_BYPASS\",\"0\") or \"0\").strip().lower() in {\"1\",\"true\",\"t\",\"yes\",\"y\"}:",
    "    sys.stderr.write(\"[pre-push] bypass enabled via AGENT_MAIL_BYPASS=1\\n\")",
    "    sys.exit(0)",
    "AGENT_NAME = os.environ.get(\"AGENT_NAME\")",
    "if not AGENT_NAME:",
    "    sys.stderr.write(\"[pre-push] AGENT_NAME environment variable is required.\\n\")",
    "    sys.exit(1)",
    "if not FILE_RESERVATIONS_DIR.exists():",
    "    sys.exit(0)",
    "",
    "# Read tuples from STDIN: <local ref> <local sha> <remote ref> <remote sha>",
    "tuples = []",
    "for line in sys.stdin.read().splitlines():",
    "    parts = line.strip().split()",
    "    if len(parts) >= 4:",
    "        tuples.append((parts[0], parts[1], parts[2], parts[3]))",
    "",
    "changed = []",
    "commits = []",
    "for local_ref, local_sha, remote_ref, remote_sha in tuples:",
    "    if not local_sha:",
    "        continue",
    "    # Enumerate commits to be pushed using remote name from args (argv[1]) when available",
    "    remote = (sys.argv[1] if len(sys.argv) > 1 else \"origin\")",
    "    try:",
    "        cp = subprocess.run([\"git\",\"rev-list\",\"--topo-order\",local_sha,\"--not\",f\"--remotes={remote}\"],",
    "                            check=True,capture_output=True,text=True)",
    "        for sha in cp.stdout.splitlines():",
    "            if sha:",
    "                commits.append(sha.strip())",
    "    except Exception:",
    "        # Fallback: gather changed paths directly when range enumeration fails",
    "        rng = local_sha if (not remote_sha or set(remote_sha) == {\"0\"}) else f\"{remote_sha}..{local_sha}\"",
    "        try:",
    "            cp = subprocess.run([\"git\",\"diff\",\"--name-status\",\"-M\",\"-z\",rng],check=True,capture_output=True)",
    "            data = cp.stdout.decode(\"utf-8\",\"ignore\")",
    "            parts = [p for p in data.split(\"\\x00\") if p]",
    "            i = 0",
    "            while i < len(parts):",
    "                status = parts[i]",
    "                i += 1",
    "                if status.startswith(\"R\") and i + 1 < len(parts):",
    "                    oldp = parts[i]; newp = parts[i + 1]; i += 2",
    "                    if oldp: changed.append(oldp)",
    "                    if newp: changed.append(newp)",
    "                else:",
    "                    if i < len(parts):",
    "                        pth = parts[i]; i += 1",
    "                        if pth: changed.append(pth)",
    "        except Exception:",
    "            pass",
    "",
    "# changed already initialized above; add per-commit changed paths (capture renames)",
    "for c in commits:",
    "    try:",
    "        cp = subprocess.run([\"git\",\"diff-tree\",\"-r\",\"--no-commit-id\",\"--name-status\",\"-M\",\"--no-ext-diff\",\"--diff-filter=ACMRDTU\",\"-z\",c],",
    "                            check=True,capture_output=True)",
    "        data = cp.stdout.decode(\"utf-8\",\"ignore\")",
    "        parts = [p for p in data.split(\"\\x00\") if p]",
    "        i = 0",
    "        while i < len(parts):",
    "            status = parts[i]",
    "            i += 1",
    "            if status.startswith(\"R\") and i + 1 < len(parts):",
    "                oldp = parts[i]; newp = parts[i + 1]; i += 2",
    "                if oldp: changed.append(oldp)",
    "                if newp: changed.append(newp)",
    "            else:",
    "                if i < len(parts):",
    "                    pth = parts[i]; i += 1",
    "                    if pth: changed.append(pth)",
    "    except Exception:",
    "        continue",
    "",
    "# Local conflict detection against FILE_RESERVATIONS_DIR using changed paths",
    "if not changed:",
    "    sys.exit(0)",
    "def _now_utc():",
    "    return datetime.now(timezone.utc)",
    "def _parse_iso(value):",
    "    if not value:",
    "        return None",
    "    try:",
    "        text = value",
    "        if text.endswith(\"Z\"):",
    "            text = text[:-1] + \"+00:00\"",
    "        dt = datetime.fromisoformat(text)",
    "        if dt.tzinfo is None or dt.tzinfo.utcoffset(dt) is None:",
    "            dt = dt.replace(tzinfo=timezone.utc)",
    "        return dt.astimezone(timezone.utc)",
    "    except Exception:",
    "        return None",
    "def _not_expired(expires_ts):",
    "    parsed = _parse_iso(expires_ts)",
    "    if parsed is None:",
    "        return True",
    "    return parsed > _now_utc()",
    "def _compile_one(patt):",
    "    q = patt.replace(\"\\\\\",\"/\")",
    "    if _PS and _GWM:",
    "        try:",
    "            return _PS.from_lines(_GWM, [q])",
    "        except Exception:",
    "            return None",
    "    return None",
    "",
    "# Phase 1: Pre-load and compile all reservation patterns ONCE",
    "compiled_patterns = []",
    "all_pattern_strings = []",
    "seen_ids = set()",
    "try:",
    "    for f in FILE_RESERVATIONS_DIR.iterdir():",
    "        if not f.name.endswith('.json'):",
    "            continue",
    "        try:",
    "            data = json.loads(f.read_text(encoding='utf-8'))",
    "        except Exception:",
    "            continue",
    "        recs = data if isinstance(data, list) else [data]",
    "        for r in recs:",
    "            if not isinstance(r, dict):",
    "                continue",
    "            rid = r.get('id')",
    "            if rid is not None:",
    "                rid_key = str(rid)",
    "                if rid_key in seen_ids:",
    "                    continue",
    "                seen_ids.add(rid_key)",
    "            patt = (r.get('path_pattern') or '').strip()",
    "            if not patt:",
    "                continue",
    "            holder = (r.get('agent') or '').strip()",
    "            exclusive = r.get('exclusive', True)",
    "            expires = (r.get('expires_ts') or '').strip()",
    "            if not exclusive:",
    "                continue",
    "            if holder and holder == AGENT_NAME:",
    "                continue",
    "            if not _not_expired(expires):",
    "                continue",
    "            # Pre-compile pattern ONCE (not per-path)",
    "            spec = _compile_one(patt)",
    "            patt_norm = patt.replace('\\\\','/').lstrip('/')",
    "            compiled_patterns.append((spec, patt, patt_norm, holder))",
    "            all_pattern_strings.append(patt_norm)",
    "except Exception:",
    "    compiled_patterns = []",
    "    all_pattern_strings = []",
    "",
    "# Phase 2: Build union PathSpec for fast-path rejection",
    "union_spec = None",
    "if _PS and _GWM and all_pattern_strings:",
    "    try:",
    "        union_spec = _PS.from_lines(_GWM, all_pattern_strings)",
    "    except Exception:",
    "        union_spec = None",
    "",
    "# Phase 3: Check changed paths against compiled patterns",
    "conflicts = []",
    "if compiled_patterns:",
    "    for p in changed:",
    "        norm = p.replace('\\\\','/').lstrip('/')",
    "        # Fast-path: if union_spec exists and path doesn't match ANY pattern, skip",
    "        if union_spec is not None and not union_spec.match_file(norm):",
    "            continue",
    "        # Detailed matching for conflict attribution",
    "        for spec, patt, patt_norm, holder in compiled_patterns:",
    "            matched = spec.match_file(norm) if spec is not None else _fn.fnmatch(norm, patt_norm)",
    "            if matched:",
    "                conflicts.append((patt, p, holder))",
    "if conflicts:",
    "    sys.stderr.write(\"Exclusive file_reservation conflicts detected\\n\")",
    "    for patt, path, holder in conflicts[:10]:",
    "        sys.stderr.write(f\"- {path} matches {patt} (holder: {holder})\\n\")",
    "    if ADVISORY:",
    "        sys.exit(0)",
    "    sys.exit(1)",
    "sys.exit(0)"
  ] ++ "\n"

/-- Check if a file starts with our chain-runner marker -/
def isChainRunnerContent (content : String) : Bool :=
  (content.find? chainRunnerMarker).isSome

/-- Check if a file starts with our guard plugin marker -/
def isGuardPluginContent (content : String) : Bool :=
  (content.find? guardPluginMarker).isSome

/-- Result of guard installation -/
structure InstallResult where
  hook : String
  deriving Repr

instance : Lean.ToJson InstallResult where
  toJson r := Lean.Json.mkObj [
    ("hook", Lean.Json.str r.hook)
  ]

/-- Result of guard uninstallation -/
structure UninstallResult where
  removed : Bool
  deriving Repr

instance : Lean.ToJson UninstallResult where
  toJson r := Lean.Json.mkObj [
    ("removed", Lean.Json.bool r.removed)
  ]

end AgentMail.Git.Guard
